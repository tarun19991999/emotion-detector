import streamlit as st
from transformers import DistilBertTokenizer, DistilBertForSequenceClassification
import torch

st.set_page_config(page_title="ðŸŽ­ Emotion Detector", layout="centered")
st.title("ðŸŽ­ Emotion Detector 3000")
st.markdown("Type your feeling and let the AI guess your vibe!")

# Use correct model name
MODEL_NAME = "bhadresh-savani/distilbert-base-uncased-emotion"

@st.cache_data(show_spinner=False)
def load_model():
    tokenizer = DistilBertTokenizer.from_pretrained(MODEL_PATH)
    model = DistilBertForSequenceClassification.from_pretrained(MODEL_PATH)
    model.eval()  
    return tokenizer, model



tokenizer, model = load_model()
id2label = model.config.id2label

# Demo media assets
emotion_gifs = {
    "joy": "https://media.giphy.com/media/yoJC2A59OCZHs1LXvW/giphy.gif",
    "sadness": "https://media.giphy.com/media/ROF8OQvDmxytW/giphy.gif",
    "anger": "https://media.giphy.com/media/l3vR9O2qfKAGTjCo0/giphy.gif",
    "neutral": "https://media.giphy.com/media/3og0IPxMM0erATueVW/giphy.gif"
}
emotion_music = {
    "joy": "https://www.soundhelix.com/examples/mp3/SoundHelix-Song-2.mp3",
    "sadness": "https://www.soundhelix.com/examples/mp3/SoundHelix-Song-10.mp3",
    "anger": "https://www.soundhelix.com/examples/mp3/SoundHelix-Song-3.mp3",
    "neutral": "https://www.soundhelix.com/examples/mp3/SoundHelix-Song-12.mp3"
}

# UI input
user_input = st.text_area("What's on your mind?", placeholder="E.g., I feel like dancing in the rain...")

if st.button("ðŸ”® Analyze My Mood") and user_input.strip():
    inputs = tokenizer(user_input, return_tensors="pt", truncation=True, padding=True)
    inputs = {k: v.to("cpu") for k, v in inputs.items()}  # âœ… Inputs to CPU

    with torch.no_grad():
        outputs = model(**inputs)

    logits = outputs.logits.detach().cpu()  # âœ… Detach and move to CPU
    probs = torch.nn.functional.softmax(logits, dim=1)
    top_pred = torch.argmax(probs, dim=1).item()
    label = id2label[str(top_pred)]
    confidence = float(probs[0][top_pred]) * 100

    st.success(f"ðŸŽ¯ Emotion: **{label.upper()}**\nðŸ§  Confidence: **{confidence:.2f}%**")
    st.image(emotion_gifs.get(label.lower(), emotion_gifs["neutral"]), caption=f"{label.capitalize()} GIF")
    st.audio(emotion_music.get(label.lower(), emotion_music["neutral"]))
